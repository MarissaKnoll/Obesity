---
title: "R Notebook"
output: html_notebook
---

```{r}
library("tidyr")
library('ggplot2')
library('dplyr')
library("glue")

wkdir = "~/Desktop/GitHub/Obesity/NewExtractions/H9N2/timo_0.01"
setwd(wkdir)
savedir = "~/Desktop/GitHub/Obesity/NewExtractions/H9N2/timo_0.01/Output_Figures"

source("~/Desktop/GitHub/Obesity/NewExtractions/H9N2/FD_functions.R")
```

```{r}
diet = c("Obese","Lean","Control")
dietColors = c("#FF9933","#66CCFF","#606060")
names(dietColors) = diet
DietcolScale_fill <- scale_fill_manual(name = "grp",values = dietColors)
DietcolScale <- scale_colour_manual(name = "grp",values = dietColors)
```

Specifying thresholds and plotting variables
```{r}
cov_cut = 200
freq_cut = 0.01
pvalcut  = 0.05

ntlist = c("A","C","G","T")
SEGMENTS = c('H9N2_PB2','H9N2_PB1','H9N2_PA','H9N2_HA','H9N2_NP','H9N2_NA','H9N2_MP','H9N2_NS')
```

#Loading metadata
This includes titer and Ct values when applicable. ND indicates qPCR was run with a negative result; 0 indicates plaque assay or HAI was run with a negative result. NA for any values indicate that data was missing. Sacrificed indicates there was no data at that time point because the ferret had already been sacrficied for pathology. 
```{r}
metafile = "~/Desktop/GitHub/Obesity/NewExtractions/H9N2/H9_Metadata.csv"

meta = read.csv(file=metafile,header=T,sep=",",na.strings = c(''))
meta = filter(meta, resequenced == "yes")

meta$Ct_Mgene = as.numeric(meta$Ct_Mgene)
meta$titer = as.numeric(meta$titer)
meta$log10_titer = as.numeric(meta$log10_titer)

meta$inf_route = factor(meta$inf_route, levels = c("Index","Contact","Aerosol","Control"))
```

Loading in coverage file & segment size information
```{r}
cov = read.csv("./avg_coverage/H9N2.coverage.csv", header = TRUE, sep = ",")

seg_sizes = "../SegmentSize.csv"
#manually changed NS size from 838 to 864 to match the longest length found in the cov data rather than the Segemnt size value from the .gtf file - think about this
sizes = read.csv(file=seg_sizes,header=T,sep=",",na.strings = c(''))
GenomeSize = (sizes %>% filter(segment == 'H9N2_GENOME'))$SegmentSize

cov$segment = factor(cov$segment, levels = SEGMENTS)
```

Checking if data passes thresholds 
```{r}
cov_check = CoverageAcross(cov,cov_cut,40,sizes, wkdir)
```

Merging coverage check info with the rest of the metadata
```{r}
meta = merge(meta, cov_check, by.x = c("sample"), by.y = c("name"), all.y = TRUE)

nrow(meta)
count(meta,quality)
```

Loading in variant files
```{r}
varfile = "./varfiles/H9N2.VariantsOnly.0.01.200.csv"

# read and rearrange the data
vars = read.csv(file=varfile,header=T,sep=",",na.strings = c(''))
vars$name = vars$sample
```

Rearranging variant dataframe
```{r}
vdf = ArrangeVarWRep(vars)
# already have replicate data in the varfiles from running CompareReps.v2.py script
vdf = vdf[!duplicated(vdf), ] %>% droplevels()
nrow(vdf)
```

Adding metadata
```{r}
vdf = merge(vdf,meta, by = c("sample","segment"))
vdf = vdf[!duplicated(vdf), ] %>% droplevels()

vdf$segment = factor(vdf$segment, levels = SEGMENTS)
```

How many unique ferrets? How many unique good quality ferrets?
```{r}
select(vdf, ferretID) %>% unique() %>% count()
#total number of unique ferrets that were sequenced

select(vdf, ferretID,quality) %>% unique() %>% filter(quality == "good") %>% nrow()
select(vdf, ferretID,quality) %>% unique() %>% filter(quality == "good")
#number of ferrets with at least one sample passing cov_check QC

filter(vdf, quality == "bad") %>% select(sample) %>% unique()
#samples that failed cov_check QC
# mostly late time points
# d02 time points: 1417 is an aerosol, most other aerosol samples weren't resequenced 
#c1913 is contact lean,1981 and 1986 and 2235 are contact obese 
```

```{r}
nrow(vdf)
vdf = filter(vdf, quality == "good") %>% unique()
nrow(vdf)

vdf = filter(vdf, sample != "2244_d12") %>% unique()
#technically passes due to the low coverage threhold needed to include W17 but has incomplete segments that aren't the Pol genes

good_names = c(levels(factor(vdf$sample)))
```

Filtering variant df by timo binocheck
```{r}
vdf$binocheck = factor(vdf$binocheck, levels = c("False","R1","R2","True"))
vdf_bino = filter(vdf, binocheck != "False")
vdf_bino = vdf_bino[!duplicated(vdf_bino), ] %>% droplevels()
nrow(vdf_bino)
# this really gets rid of a lot of variants (~1000)
```

Filtering variant df with frequency cutoffs
```{r}
nrow(vdf)
vdf = filter(vdf, minorfreq1 >= freq_cut & 
               minorfreq2 >= freq_cut & 
               minor %in% ntlist &
               major %in% ntlist) %>% 
            droplevels()
# based on MAF study, reps and 0.01% cutoff was best combo
#filter each replicate separately rather than using the average
nrow(vdf)
# does not eliminate any variants here

vdf = filter(vdf, inf_route == "Index" | inf_route == "Contact" | inf_route == "Control") %>% unique()
# ignoring aerosol for now
```

How many variants per sample?
```{r}
nums = vdf %>% group_by(sample) %>% tally()
range(nums$n)
mean(nums$n)

ggplot(nums, aes(x = n)) +
  geom_histogram(binwidth = 1) +
  PlotTheme1
```

```{r}
transmission_info = "/Users/marissaknoll/Desktop/GitHub/Obesity/NewExtractions/H9N2/TransmissionPairs.csv"
pairs = read.csv(transmission_info, header = T)
```

```{r}
fercount = select(vdf,sample,ferretID,DPI,diet,inf_route)
fercount = fercount[!duplicated(fercount), ]  %>% 
  unique() %>% 
  group_by(sample,diet,inf_route,DPI) %>% 
  tally()

fercount = separate(fercount,sample,into = c("ferretID","DPI"))
fercount = merge(fercount, pairs, by = c("ferretID"))
  
p1 = fercount %>% unique() %>% 
    ggplot(., aes(x= DPI, y = pair_numbers, fill = diet)) + 
    geom_tile(color = 'black') + 
    PlotTheme3 +
    DietcolScale_fill + 
    facet_grid(pair_diets~inf_route, scales = 'free', space = 'free')
print(p1)
ggsave("ferrets_tileplot.pdf", p1, path = savedir,)
```

```{r}
con_change = filter(vdf, stocknt != major) %>%
  filter(major %in% ntlist)
con_change = con_change[!duplicated(con_change), ]
con_change$var = paste0(con_change$ferretID,"_",con_change$segment,"_",
                        con_change$major,"_",con_change$ntpos,"_",con_change$minor)
consensus = unique(con_change$var)
length(consensus)
```

```{r}
vdf$var = paste0(vdf$ferretID,"_",vdf$segment,"_",vdf$major,"_",vdf$ntpos,"_",vdf$minor)

minorvdf = filter(vdf, !(var %in% consensus))
minorvdf = minorvdf[!duplicated(minorvdf), ]
nrow(vdf) - nrow(minorvdf)
```

```{r}
freq_dist = ggplot() +
  geom_histogram(aes(x = minorfreq, fill = diet), filter(vdf, inf_route == "Index"), binwidth = 0.025) +
  geom_histogram(aes(x = majorfreq, fill = diet), filter(con_change, inf_route == "Index"), binwidth = 0.025) +
  facet_grid(~diet) +
  PlotTheme1 +
  DietcolScale_fill
print(freq_dist)
ggsave(freq_dist, file = "freq_dist.pdf", path = savedir)

o_freq = filter(vdf, inf_route == "Index" & diet == "Obese")
l_freq = filter(vdf, inf_route == "Index" & diet == "Lean")
t.test(o_freq$minorfreq, l_freq$minorfreq)
```

Tallying SNVs
```{r}
# can make these groupings whatever you want

# count the number of SNVs per sample
group_list_seg = c('ferretID','segment',"DPI","diet","inf_route","cohort") # counts across each segment 
group_list_gen = c('ferretID',"DPI","diet","inf_route","cohort") # Counts across entire genome

seg_count = TallyIt(vdf, group_list_seg, "snv_count")
gen_count = TallyIt(vdf, group_list_gen, "snv_count") 
```

```{r}
# INCLUDING SEGMENTS WITH NO SNVS - but only using those that passed seq cutoff
reseq_seg = select(meta,ferretID,segment,DPI,diet,inf_route,cohort, quality) %>% 
  filter(quality == "good") %>% 
  unique()
seg_count = merge(seg_count,reseq_seg, all= TRUE)
seg_count = seg_count[!duplicated(seg_count), ]

seg_count$snv_count[is.na(seg_count$snv_count)] = 0
seg_count = filter(seg_count, !is.na(ferretID))
```

```{r}
reseq_gen = select(meta,ferretID,DPI,diet,inf_route,cohort,quality) %>% 
  filter(quality == "good") %>% 
  unique()
gen_count = merge(gen_count,reseq_gen, all = TRUE)
gen_count = gen_count[!duplicated(gen_count), ]

gen_count$snv_count[is.na(gen_count$snv_count)] = 0
gen_count = filter(gen_count, !is.na(ferretID))
```

```{r}
# Average Number of Variants per Sample
gen_count_avg = group_by(gen_count, DPI, diet, inf_route) %>%
  mutate(avgSNV = mean(snv_count), sdSNV = sd(snv_count))

seg_count_avg = group_by(seg_count, DPI, diet) %>%
  mutate(avgSNV = mean(snv_count), sdSNV = sd(snv_count))
```

```{r}
snv_count_segment_plot = filter(seg_count, inf_route == "Index") %>% 
  filter(DPI == "d02" | DPI == "d04" | DPI == "d06") %>%

ggplot(. , aes(x = segment, y = snv_count, color = diet)) +
  geom_boxplot(outlier.shape = NA) +
  #geom_jitter(width = 0.2, aes(color = diet)) +
  facet_grid(~DPI) +
  PlotTheme1 +
  DietcolScale
print(snv_count_segment_plot)
ggsave("snv_count_segment_plot.pdf", snv_count_segment_plot, path = savedir, width = 10, height = 5)


gen_count_segment_plot = filter(gen_count, inf_route == "Index" | inf_route == "Control") %>% 
  filter(DPI == "d02" | DPI == "d04" | DPI == "d06" | DPI == "Stock") %>%
ggplot(. , aes(x = diet, y = snv_count)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.2, aes(color = diet)) +
  facet_grid(~DPI) +
  ylab("SNV richness per sample") +
  PlotTheme1 +
  DietcolScale
print(gen_count_segment_plot)
ggsave("gen_count_segment_plot.pdf",gen_count_segment_plot,path=savedir, width = 10, height = 5)

seg_count$diet_segment = paste0(seg_count$diet,"_",seg_count$segment)
seg_count$diet_segment = factor(seg_count$diet_segment, 
                                levels =c ('Control_H9N2_PB2','Lean_H9N2_PB2','Obese_H9N2_PB2',
                                           'Control_H9N2_PB1','Lean_H9N2_PB1','Obese_H9N2_PB1',
                                           'Control_H9N2_PA','Lean_H9N2_PA','Obese_H9N2_PA',
                                           'Control_H9N2_HA','Lean_H9N2_HA','Obese_H9N2_HA',
                                           'Control_H9N2_NP','Lean_H9N2_NP','Obese_H9N2_NP',
                                           'Control_H9N2_NA','Lean_H9N2_NA','Obese_H9N2_NA',
                                           'Control_H9N2_MP','Lean_H9N2_MP','Obese_H9N2_MP',
                                           'Control_H9N2_NS','Lean_H9N2_NS','Obese_H9N2_NS'))

seg_count_segment_plot = filter(seg_count, inf_route == "Index" | inf_route == "Control") %>% 
  filter(DPI == "d02" | DPI == "d04" | DPI == "d06" | DPI == "Stock") %>%
ggplot(. , aes(x = diet_segment, y = snv_count)) +
  geom_boxplot(outlier.shape = NA, position = "dodge", aes(color = diet)) +
  #geom_jitter(width = 0.2, aes(color = diet)) +
  facet_grid(~DPI) +
  ylab("SNV richness per sample per segment") +
  PlotTheme1 +
  DietcolScale
print(seg_count_segment_plot)
ggsave("seg_count_segment_plot.pdf",seg_count_segment_plot,path=savedir, width = 10, height = 5)
# 03/07 now includes consensus changes (using vdf instead of minorvdf)
```

T test for segment comparisons
```{r}
o = filter(seg_count, inf_route == "Index" & diet == "Obese" & DPI == "d06" & segment == "H9N2_NS")
l = filter(seg_count, inf_route == "Index" & diet == "Lean" & DPI == "d06" & segment == "H9N2_NS")
t.test(o$snv_count, l$snv_count)

# d06: PB1, PA, NA are sig. diff
# nothing else is sig. diff

o_gen = filter(gen_count, inf_route == "Index" & diet == "Obese" & DPI == "d06")
l_gen = filter(gen_count, inf_route == "Index" & diet == "Lean" & DPI == "d06")
t.test(o_gen$snv_count, l_gen$snv_count)
```

Calculating Shannon Entropy
```{r}
vdf = ShannonPos(vdf)
vdf$SegmentSize = as.numeric(vdf$SegmentSize)
vdf$shannon_perkb = (vdf$segment_shan/(vdf$SegmentSize/1000))
vdf$normalized_shannon = (vdf$shannon/GenomeSize)
```

```{r}
# shannon_ntpos = shannon entropy at that nt pos - should always be between 0 and 1 for each sample
# segment_shan = sum of all nt_pos per segment for each sample
# shannon = sum of all segment_shan across genome for each sample
# shannon_perkb = segment shannon per kb (segment specific) for each sample
# normalized_shannon = shannon divided by genome size (can make per kb by dividing by 1000) for each sample
```

```{r}
# Average Shannon Entropy per Site per Sample (using normalized_shannon)
shan_g = ungroup(vdf) %>%
  select(ferretID, DPI, diet, inf_route, cohort,normalized_shannon) %>%
  unique()

shan_g = merge(shan_g,reseq_gen %>% unique(), by = c("ferretID", "DPI", "diet", "inf_route","cohort"), all= TRUE) %>%
  filter(inf_route == "Index" | inf_route == "Control") %>% 
  unique()
shan_g$normalized_shannon[is.na(shan_g$normalized_shannon)] = 0

dim(shan_g)
shan_g <- shan_g[complete.cases(shan_g), ] 
dim(shan_g)

shan_gen_plot = ggplot(filter(shan_g, DPI == "d02" | DPI == "d04" | DPI == "d06" | DPI == "Stock"), 
       aes(x = diet, y = normalized_shannon/1000)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.2, aes(color = diet)) +
  facet_grid(~DPI) +
  xlab("Normalized Shannon entropy per kB") +
  PlotTheme1 +
  DietcolScale
print(shan_gen_plot)
ggsave("shan_gen_plot.pdf", shan_gen_plot, path = savedir, width = 10, height = 5)

# 03/07 now includes consensus changes (using vdf instead of minorvdf)
```

Test for significance
```{r}
o = filter(shan_g, DPI == "Stock" & diet == "Control")
l = filter(shan_g, DPI == "d06" & diet == "Lean")
t.test(o$normalized_shannon,l$normalized_shannon)
```

Does higher titer correlate with more diversity?
```{r}
titers = select(meta, sample, ferretID, DPI, titer, log10_titer)
gen_count_titers = merge(gen_count, titers, by = c("ferretID","DPI"))

Titer_SNV_Corr = ggplot(filter(gen_count_titers, log10_titer > 1), aes(x = log10_titer, y = snv_count)) +
  geom_point() +
  geom_smooth(method = "glm") +
  facet_grid(~inf_route) +
  PlotTheme1
print(Titer_SNV_Corr)
ggsave(Titer_SNV_Corr, file = "Titer_SNV_Corr.pdf", path = savedir)
```

dNdS analysis
```{r}
# by ferret
#dNdS_ferret = minorvdf %>% 
#  ungroup() %>% 
#  group_by(ferretID,DPI,diet,inf_route) %>% 
#  count(nonsyn)

#dNdS_ferret = pivot_wider(dNdS_ferret,names_from = nonsyn, values_from = n)
#dNdS_ferret = select(dNdS_ferret, ferretID,DPI,nonsyn,syn)
#dNdS_ferret$dNdS = paste0(dNdS_ferret$nonsyn / dNdS_ferret$syn)
#dNdS_ferret$dNdS = as.numeric(dNdS_ferret$dNdS)

#dNdS_ferret = filter(dNdS_ferret, inf_route == "Index" | inf_route == "Contact")

#dNdS_ferret_plot = ggplot(dNdS_ferret, aes(x = DPI, y = dNdS, color = ferretID)) +
#  geom_point() +
#  geom_line(aes(group = ferretID)) +
#  facet_grid(~diet+inf_route) +
#  PlotTheme1
#print(dNdS_ferret_plot)
#ggsave("dNdS_ferret.pdf", dNdS_ferret_plot, path = savedir)
#ggsave("dNdS_ferret.png", dNdS_ferret_plot, path = savedir, width = 10, height = 5)
```

Setting up AF dataframes for bottleneck calculation: Stock to index ferrets
```{r}
af_df = select(vdf, sample, segment, ntpos, stocknt, major, minor,minorfreq, cohort, inf_route, ferretID, diet, DPI) %>%
  ungroup() %>%
  unique()
af_df$var = paste0(af_df$segment,"_",af_df$major,"_",af_df$ntpos,"_",af_df$minor)

stock = filter(af_df, inf_route == "Control") %>% unique()
index = filter(af_df, inf_route == "Index") %>% unique()

samples = unique(index$sample)
  
stock_files_dir = "~/Desktop/GitHub/Obesity/NewExtractions/H9N2/timo_0.01/freqfiles/stock"
data = data.frame()
  
for(i in samples){
  print(i)
  
  n = filter(af_df, sample == i)
  
  c = unique(n$cohort)
  s = filter(stock, cohort %in% c)
  
  comp = merge(s, n, by = c("segment", "ntpos","stocknt","major","minor","cohort","var"), all.x = TRUE)
  comp$minorfreq.y[is.na(comp$minorfreq.y)] = 0
  
  df = select(comp,minorfreq.x,minorfreq.y)
  write.table(df, file = glue("{stock_files_dir}/Stock_{i}_freqs.csv"), row.names = FALSE, col.names = FALSE)
  
  var_af = select(comp, var, minorfreq.x,minorfreq.y) %>% 
    mutate(sample = i)
  data = rbind(data,var_af)
}
```

What happens to the stock variants in the index(af)?
```{r}
lowest_timepoint = c("1408_d02","1414_d04","1416_d02","1789_d02","1800_d02","1801_d02","1910_d02","1912_d02",
                     "1968_d02","1970_d02","1972_d02","1973_d02","1974_d02","1975_d04","1977_d02","1984_d02",
                     "2233_d04","2234_d04","2240_d04","2251_d04","2253_d04","2254_d02")
data = data %>% 
  filter(sample %in% lowest_timepoint) %>% 
  group_by(sample)
write.table(data, file = "stock_variants_index.csv", sep = ",", row.names = FALSE)
# I'm dumb and could do this faster in excel than figuring out the code for it - go back and adjust
df = read.csv("~/Desktop/GitHub/Obesity/NewExtractions/H9N2/timo_0.01/stock_variants_index_kl.csv")
meta_noseg = select(meta, sample, ferretID, DPI, cohort, inf_route, diet, STRAIN, quality) %>% unique()

df1 = group_by(df, sample) %>% 
  count(dynamics) %>% 
  filter(n != 18) %>% 
  # one weird empty row with an n of 18 at the top, get rid of this
  pivot_wider(names_from = dynamics, values_from = n) %>%
  mutate(totalvar = kept +lost) %>%
  mutate(percent_lost = lost/totalvar)

df1 = merge(df1, meta_noseg, by = c("sample"))

stock_lost = ggplot(df1, aes(x = diet, y = percent_lost)) +
  geom_boxplot() +
  geom_jitter(aes(color = diet), width = 0.2) +
  PlotTheme1 +
  DietcolScale
print(stock_lost)
ggsave(stock_lost, file = "stock_lost.pdf", path = savedir)

o = filter(df1, diet == "Obese")
l = filter(df1, diet == "Lean")
t.test(o$percent_lost, l$percent_lost)
mean(o$percent_lost)
mean(l$percent_lost)
mean(df1$percent_lost)
```
What happens to the variants in the stock in the index ferrets? (af)
```{r}
kept = filter(df, dynamics == "kept")
keep_vars = unique(kept$var)

vdf_stocks = filter(vdf, inf_route == "Index")
vdf_stocks$ntvar = paste0(vdf_stocks$segment,"_",vdf_stocks$major,"_",vdf_stocks$ntpos,"_",vdf_stocks$minor)
vdf_stocks = filter(vdf_stocks, ntvar %in% keep_vars)

stockvar_index = ggplot(filter(vdf_stocks, inf_route == "Index"), aes(x = DPI, y = minorfreq, color = diet)) +
  geom_point() +
  geom_line(aes(group = ferretID)) +
  facet_grid(~ntvar) +
  PlotTheme1 +
  DietcolScale
print(stockvar_index)
ggsave(stockvar_index, file = "stockvar_index.pdf",path = savedir, width = 10, height = 5)
 ```

Loading in data after running bottleneck code
```{r}
stock_index = read.csv("~/Desktop/GitHub/Obesity/NewExtractions/H9N2/timo_0.01/freqfiles/stock/all_stock_bottlenecks.csv")
stock_index = merge(stock_index, meta_noseg, by = c("sample","ferretID","DPI"))
```

```{r}
ggplot(filter(stock_index, smallest_timepoint == "yes"), aes(x = diet, y = bottleneck_size)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.2, aes(color = diet)) +
  PlotTheme1 +
  DietcolScale +
  ggtitle("Bottleneck between stock and index ferrets")

o_bottle = filter(stock_index, diet == "Obese" & smallest_timepoint == "yes")
l_bottle = filter(stock_index, diet == "Lean" & smallest_timepoint == "yes")
t.test(o_bottle$bottleneck_size, l_bottle$bottleneck_size)
```

Turnover rate
```{r}
multiday = ungroup(minorvdf) %>%
  filter(inf_route == "Index") %>%
  select(ferretID, DPI) %>% 
  unique() %>%
  group_by(ferretID) %>%
  tally() %>%
  filter(n > 1)

select_samps = c("2254")
  unique(multiday$ferretID)

for(i in select_samps){
  
  print(i)
  df = filter(minorvdf, ferretID == i)
  print(head(df))
  days = unique(df$DPI)
  print(days)
  
  df_day = group_by(df, DPI) %>% tally()
  print(df_day)
}
```

Setting up AF dataframes for bottleneck calculation: Index to contact ferrets
```{r}
af_df = select(vdf, sample, segment, ntpos, stocknt, major, minor,minorfreq, cohort, inf_route, ferretID, diet, DPI) %>%
  ungroup() %>%
  unique()
af_df$var = paste0(af_df$segment,"_",af_df$major,"_",af_df$ntpos,"_",af_df$minor)
df = merge(af_df, pairs, by = c("ferretID"))

index = filter(df, inf_route == "Index") %>% unique()
first_time = c("1409_d04","1410_d02","1415_d02","1794_d02","1797_d02",
               "1913_d06","1914_d06","1980_d02","1981_d10","1986_d10","2231_d04","2232_d02","2239_d04","2243_d04")
contact = filter(df, sample %in% first_time) %>% unique()

samples = unique(index$sample)
  
ferret_dir = "~/Desktop/GitHub/Obesity/NewExtractions/H9N2/timo_0.01/freqfiles/transmission"
data = data.frame()
  
for(i in samples){
  print(i)
  
  n = filter(index, sample == i)
  partner = unique(n$pair_numbers)
  c = filter(contact, pair_numbers %in% partner)
  
  if(nrow(c) > 0){
    
    s = unique(c$sample)
  
    comp = merge(n, c, by = c("segment", "ntpos","stocknt","major","minor","cohort","var"), all.x = TRUE)
    comp$minorfreq.y[is.na(comp$minorfreq.y)] = 0
  
    df = select(comp,minorfreq.x,minorfreq.y)
    write.table(df, file = glue("{ferret_dir}/{i}_{s}_freqs.csv"), row.names = FALSE, col.names = FALSE)
    
  }else(print("No transmission"))
  
  
  #var_af = select(comp, var, minorfreq.x,minorfreq.y) %>% 
  #  mutate(sample = i)
  #data = rbind(data,var_af)
}
```